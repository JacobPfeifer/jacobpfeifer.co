---
title: COVID-19 Data Project
date: 2021-08-17
summary: Scraping and visualizing the COVID-19 pandemic in Sedgwick County, KS.
img: /content/images/sg-co-script.png
alt: Python Script used to harvest data from the Sedgwick County COVID Dashboard
skill: [Programming,Data Viz]
tool: [Python,Tableau]
role: Personal Project
timeline: March - August 2020
---
<h2 class="font-serif">Background</h2>

<p>Early in the pandemic, Sedgwick County was reporting the total number of cases and deaths via a daily PDF. To see how many new cases and deaths were reported each day, you needed to compare it with the previous day's PDF. I wanted to better understand my county's trajectory and how I should shape behavior in response. Intially, I made a spreadsheet and manually entered the data from the daily PDFs. This allowed me to see the delta each day. Sedgwick County eventually released a <a target="blank" href="https://sedgwickcounty.maps.arcgis.com/apps/dashboards/7b2b4364a5fa4ba3a015d52450acfe0d">dashboard.</a> The dashboard made it easier to see how many cases, hospitalizations, and deaths were reported each day but I thought there was an opportunity to tell a more complete story.</p>

<p>Goals:
    <ul>
        <li>Create better looking and more informative charts for myself, friends and family.</li>>
        <li>Showcase metics not on display (Case Fatality Rate, Positivity Rate, 7-Day-Moving Average)</li>
    </ul>
</p>

<h2 class="font-serif">Solution</h2>

<p>First, I needed a more efficent way to keep my database current. Poking through the dev tools I found a <a target="blank" href="https://services7.arcgis.com/McLat6HlPl45bNBv/ArcGIS/rest/services">public directory</a> that hosted the dashboard data. I was able to get almost everything from this directory via an API call, but some data was missing. More on that soon.</p>

{% set modal_img = "/content/images/dev-tools.png" %}
{% set modal_alt = "Using the Chrome Dev Tools to find the URLs the data is coming from" %}
{% include "components/lightbox.njk" %} 

<p><a target="blank" href="https://www.tableau.com">Tableau</a>, the data visualization tool I used, automatically updates charts if Google Sheets is used as the database. I used <a target="blank" href="https://github.com/bradjasper/ImportJSON">ImportJSON</a> to import the data from the county directory.</p>

<p>Then I needed to figure out how to get the two attributes I was missing: how many positive and negative tests were reported each day. The only way to get this data was writing a custom web scraper. After doing some research, I decided to use <a target="blank" href="https://www.selenium.dev/selenium/docs/api/py/">Selenium</a> which is written in Python. Selenium runs a browser instance, allowing it to interact with elements and reveal data that is not visible.</p>

<h2 class="font-serif">Deliverable</h2>

<p>10 tutorials followed and 10,000 errors pasted into Google later, I had a working script. I'm sure my code is full of inefficencies, but it does the job. Here's the order of operations:
</p>
<ol>
    <li>Launch a browser window at the dashboard URL</li>
    <li>Expand the range of the chart to include all historical data</li>
    <li>Show the chart data in a table view</li>
    <li>Harvest the Dates, Positive Tests, and Negative Tests</li>
    <li>Orgainze that data into container that can be easily transformed into JSON</li>
    <li>Post that data to JSONbin</li>
</ol>

<div style="width:100%;height:0px;position:relative;padding-bottom:59.900%;"><iframe src="https://streamable.com/e/n2oyxn?loop=0" frameborder="0" width="100%" height="100%" allowfullscreen style="width:100%;height:100%;position:absolute;left:0px;top:0px;overflow:hidden;"></iframe></div>
<p class="text-sm text-gray-500">Script in action</p>
<hr class="mt-0 mb-4">

<h3 class="font-medium font-serif">covid-scraper.py</h2>

{% include "components/covidmodal.njk" %}